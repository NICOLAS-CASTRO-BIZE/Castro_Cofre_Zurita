{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (0.3.7)\n",
      "Requirement already satisfied: langchain_community in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (0.3.7)\n",
      "Requirement already satisfied: langchain_chroma in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (0.1.4)\n",
      "Requirement already satisfied: langchain_text_splitters in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (0.3.2)\n",
      "Requirement already satisfied: langchain_huggingface in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (3.3.0)\n",
      "Requirement already satisfied: langchain_qdrant in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: qdrant-client in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (1.12.1)\n",
      "Requirement already satisfied: langchain_ollama in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: pypdf in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (5.1.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from langchain) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from langchain) (3.11.2)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from langchain) (0.3.19)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from langchain) (0.1.143)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from langchain_community) (2.6.1)\n",
      "Requirement already satisfied: chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from langchain_chroma) (0.5.18)\n",
      "Requirement already satisfied: fastapi<1,>=0.95.2 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from langchain_chroma) (0.115.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from langchain_huggingface) (0.26.2)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from langchain_huggingface) (0.20.3)\n",
      "Requirement already satisfied: transformers>=4.39.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from langchain_huggingface) (4.46.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from sentence-transformers) (4.67.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from sentence-transformers) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from sentence-transformers) (1.14.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: grpcio>=1.41.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from qdrant-client) (1.68.0)\n",
      "Requirement already satisfied: grpcio-tools>=1.41.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from qdrant-client) (1.68.0)\n",
      "Requirement already satisfied: httpx>=0.20.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from httpx[http2]>=0.20.0->qdrant-client) (0.27.2)\n",
      "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from qdrant-client) (2.10.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from qdrant-client) (2.2.3)\n",
      "Requirement already satisfied: ollama<1,>=0.3.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from langchain_ollama) (0.3.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.1)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.2.2.post1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.7.6)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.32.0)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (3.7.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (4.12.2)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.19.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.28.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.28.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.49b1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.28.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (6.4.5)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (4.2.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.13.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (31.0.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (4.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (3.10.11)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (13.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.23.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from fastapi<1,>=0.95.2->langchain_chroma) (0.41.2)\n",
      "Requirement already satisfied: protobuf<6.0dev,>=5.26.1 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from grpcio-tools>=1.41.0->qdrant-client) (5.28.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from grpcio-tools>=1.41.0->qdrant-client) (75.5.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (0.14.0)\n",
      "Requirement already satisfied: h2<5,>=3 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from httpx[http2]>=0.20.0->qdrant-client) (4.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (24.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (1.33)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from portalocker<3.0.0,>=2.7.0->qdrant-client) (308)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from transformers>=4.39.0->langchain_huggingface) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from transformers>=4.39.0->langchain_huggingface) (0.4.5)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.2.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (6.0.1)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (4.0.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain) (3.0.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (2.36.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (3.2.2)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.9)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (24.3.25)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.2.15)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (8.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.66.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.28.1 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.28.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.28.1 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.28.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.49b1 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.49b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.49b1 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.49b1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b1 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.49b1)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.49b1 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.49b1)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from opentelemetry-instrumentation==0.49b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.16.0)\n",
      "Requirement already satisfied: asgiref~=3.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-asgi==0.49b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (2.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (2.18.0)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.5.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.6.4)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.24.0)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (14.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (4.9)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.1.2)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (10.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (3.5.4)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "# pip install faiss-cpu sentence-transformers langchain PyPDF2\n",
    "!pip install langchain langchain_community langchain_chroma langchain_text_splitters langchain_huggingface sentence-transformers langchain_qdrant qdrant-client langchain_ollama pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para guardar las librerias requeridas\n",
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and preprocess the PDF\n",
    "\"\"\"Este módulo contiene funciones para cargar documentos PDF utilizando la biblioteca LangChain.\"\"\"\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Cargar las variables de entorno\n",
    "load_dotenv()\n",
    "\n",
    "def load_pdf(file_path: str):\n",
    "    \"\"\"\n",
    "    Carga un archivo PDF y devuelve su contenido como documentos procesados.\n",
    "\n",
    "    Args:\n",
    "        file_path: Ruta al archivo PDF a cargar.\n",
    "\n",
    "    Returns:\n",
    "        docs: Lista de documentos procesados extraídos del PDF.\n",
    "    \"\"\"\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    docs = loader.load()\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in c:\\users\\nicol\\onedrive\\mia\\cursos\\segundo bimestre\\proyecto aplicado\\proyecto\\.venv\\lib\\site-packages (5.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example file path for Brazilian food regulation PDF\n",
    "#file_path = \"/Users/carloszurita/Documents/GIT/practicos-rag/data/biblioteca-de-alimentos.pdf\"\n",
    "file_path = \"../Castro_Cofre_Zurita/data/biblioteca-de-alimentos.pdf\"\n",
    "\n",
    "pdf_text = load_pdf(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Step 2: Split the document into chunks\\ndef split_text_into_chunks(documents, output_folder: str, chunk_size: int = 1000, chunk_overlap: int = 200) -> list:\\n    \\n    Divide el texto de un conjunto de documentos en chunks, guarda cada chunk en la carpeta especificada\\n    y retorna la lista de chunks.\\n\\n    Args:\\n        documents: Lista de documentos procesados (output de PyPDFLoader).\\n        output_folder: Ruta de la carpeta donde se guardarán los chunks.\\n        chunk_size: Tamaño máximo de cada chunk en caracteres (por defecto, 1000).\\n        chunk_overlap: Cantidad de caracteres de solapamiento entre chunks (por defecto, 200).\\n\\n    Returns:\\n        chunks: Lista de chunks generados a partir del texto de los documentos.\\n\\n    import os\\n    from langchain.text_splitter import RecursiveCharacterTextSplitter\\n\\n    # Verificar que la carpeta de salida exista, si no, crearla\\n    os.makedirs(output_folder, exist_ok=True)\\n\\n    # Concatenar el texto de los documentos\\n    all_texts = [doc.page_content for doc in documents]  # Extraer texto de cada documento\\n    concatenated_text = \" \".join(all_texts)  # Concatenar en una sola cadena\\n\\n    # Crear documentos directamente desde el texto\\n    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\\n    documents = text_splitter.create_documents([concatenated_text])\\n\\n    # Dividir los documentos en chunks\\n    chunks = text_splitter.split_documents(documents)\\n\\n    # Guardar cada chunk como un archivo de texto\\n    for i, chunk in enumerate(chunks):\\n        chunk_file_path = os.path.join(output_folder, f\"chunk_{i + 1}.txt\")\\n        with open(chunk_file_path, \"w\", encoding=\"utf-8\") as file:\\n            file.write(chunk.page_content)\\n\\n    print(f\"{len(chunks)} chunks guardados en la carpeta: {output_folder}\")\\n    \\n    # Retornar los chunks\\n    return chunks\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Step 2: Split the document into chunks\n",
    "def split_text_into_chunks(documents, output_folder: str, chunk_size: int = 1000, chunk_overlap: int = 200) -> list:\n",
    "    \n",
    "    Divide el texto de un conjunto de documentos en chunks, guarda cada chunk en la carpeta especificada\n",
    "    y retorna la lista de chunks.\n",
    "\n",
    "    Args:\n",
    "        documents: Lista de documentos procesados (output de PyPDFLoader).\n",
    "        output_folder: Ruta de la carpeta donde se guardarán los chunks.\n",
    "        chunk_size: Tamaño máximo de cada chunk en caracteres (por defecto, 1000).\n",
    "        chunk_overlap: Cantidad de caracteres de solapamiento entre chunks (por defecto, 200).\n",
    "\n",
    "    Returns:\n",
    "        chunks: Lista de chunks generados a partir del texto de los documentos.\n",
    "\n",
    "    import os\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "    # Verificar que la carpeta de salida exista, si no, crearla\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Concatenar el texto de los documentos\n",
    "    all_texts = [doc.page_content for doc in documents]  # Extraer texto de cada documento\n",
    "    concatenated_text = \" \".join(all_texts)  # Concatenar en una sola cadena\n",
    "\n",
    "    # Crear documentos directamente desde el texto\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    documents = text_splitter.create_documents([concatenated_text])\n",
    "\n",
    "    # Dividir los documentos en chunks\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "    # Guardar cada chunk como un archivo de texto\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk_file_path = os.path.join(output_folder, f\"chunk_{i + 1}.txt\")\n",
    "        with open(chunk_file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(chunk.page_content)\n",
    "\n",
    "    print(f\"{len(chunks)} chunks guardados en la carpeta: {output_folder}\")\n",
    "    \n",
    "    # Retornar los chunks\n",
    "    return chunks\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_chunks(documents, chunk_size: int = 1000, chunk_overlap: int = 200) -> list:\n",
    "    \"\"\"\n",
    "    Divide el texto de un conjunto de documentos en chunks.\n",
    "\n",
    "    Args:\n",
    "        documents: Lista de documentos procesados (output de PyPDFLoader).\n",
    "        chunk_size: Tamaño máximo de cada chunk en caracteres (por defecto, 1000).\n",
    "        chunk_overlap: Cantidad de caracteres de solapamiento entre chunks (por defecto, 200).\n",
    "\n",
    "    Returns:\n",
    "        chunks: Lista de chunks generados a partir del texto de los documentos.\n",
    "    \"\"\"\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "    # Concatenar el texto de los documentos\n",
    "    all_texts = [doc.page_content for doc in documents]  # Extraer texto de cada documento\n",
    "    concatenated_text = \" \".join(all_texts)  # Concatenar en una sola cadena\n",
    "\n",
    "    # Crear documentos directamente desde el texto\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    documents = text_splitter.create_documents([concatenated_text])\n",
    "\n",
    "    # Dividir los documentos en chunks\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_chunks(chunks: list, output_folder: str):\n",
    "    \"\"\"\n",
    "    Guarda una lista de chunks en archivos de texto individuales dentro de una carpeta.\n",
    "\n",
    "    Args:\n",
    "        chunks: Lista de chunks generados.\n",
    "        output_folder: Ruta de la carpeta donde se guardarán los chunks.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    import os\n",
    "\n",
    "    # Verificar que la carpeta de salida exista, si no, crearla\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Guardar cada chunk como un archivo de texto\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk_file_path = os.path.join(output_folder, f\"chunk_{i + 1}.txt\")\n",
    "        with open(chunk_file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(chunk.page_content)\n",
    "\n",
    "    print(f\"{len(chunks)} chunks guardados en la carpeta: {output_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 chunks guardados en la carpeta: ../Castro_Cofre_Zurita/data/chunks/\n"
     ]
    }
   ],
   "source": [
    "# Ruta de la carpeta donde se guardarán los chunks\n",
    "output_folder = \"../Castro_Cofre_Zurita/data/chunks/\"\n",
    "\n",
    "# Generar los chunks\n",
    "chunks = generate_chunks(pdf_text, chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "# Guardar los chunks en la carpeta\n",
    "save_chunks(chunks, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Example file path for Brazilian food regulation PDF\\n# Ruta de la carpeta donde se guardarán los chunks\\n#output_folder = \"/Users/carloszurita/Documents/GIT/practicos-rag/data/chunks/\"\\noutput_folder = \"../Castro_Cofre_Zurita/data/chunks/\"\\n\\n# Dividir el texto en chunks y guardarlos\\nchunks=split_text_into_chunks(pdf_text, output_folder)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Example file path for Brazilian food regulation PDF\n",
    "# Ruta de la carpeta donde se guardarán los chunks\n",
    "#output_folder = \"/Users/carloszurita/Documents/GIT/practicos-rag/data/chunks/\"\n",
    "output_folder = \"../Castro_Cofre_Zurita/data/chunks/\"\n",
    "\n",
    "# Dividir el texto en chunks y guardarlos\n",
    "chunks=split_text_into_chunks(pdf_text, output_folder)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Generate embeddings using Hugging Face\n",
    "\"\"\"Este módulo contiene funciones para generar embeddings a partir de texto utilizando Hugging Face.\"\"\"\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "def generate_embeddings(chunks: list, model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\") -> tuple:\n",
    "    \"\"\"\n",
    "    Genera embeddings a partir de una lista de chunks de texto utilizando un modelo de Hugging Face.\n",
    "\n",
    "    Args:\n",
    "        chunks: Lista de textos en formato string para los cuales se generarán los embeddings.\n",
    "        model_name: Nombre del modelo preentrenado de Hugging Face a utilizar (por defecto, \"sentence-transformers/all-MiniLM-L6-v2\").\n",
    "\n",
    "    Returns:\n",
    "        embeddings: Lista de vectores de embeddings generados para los chunks de texto.\n",
    "        embedding_model: El modelo de embeddings utilizado.\n",
    "    \"\"\"\n",
    "    # Cargar el modelo de embeddings\n",
    "    embedding_model = HuggingFaceEmbeddings(model_name=model_name)\n",
    "    \n",
    "    # Generar embeddings para los chunks\n",
    "    embeddings = embedding_model.embed_documents(chunks)\n",
    "    \n",
    "    return embeddings, embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Este módulo guarda los embeddings en la carpeta embeddings como archivos JSON.\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "def save_embeddings_as_json(embeddings: list, output_folder: str = \"data/embeddings\"):\n",
    "    \"\"\"\n",
    "    Guarda una lista de embeddings en archivos JSON individuales dentro de una carpeta específica.\n",
    "\n",
    "    Args:\n",
    "        embeddings: Lista de vectores de embeddings a guardar.\n",
    "        output_folder: Ruta de la carpeta donde se guardarán los embeddings (por defecto, \"data/embeddings\").\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Crear la carpeta de salida si no existe\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Guardar cada embedding en un archivo .json separado\n",
    "    for i, embedding in enumerate(embeddings):\n",
    "        file_path = os.path.join(output_folder, f\"chunk_{i + 1}_embedding.json\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump({\"embedding\": embedding}, f, indent=4)\n",
    "\n",
    "    print(f\"{len(embeddings)} embeddings guardados en formato JSON en la carpeta: {output_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\AppData\\Local\\Temp\\ipykernel_34368\\33323915.py:19: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=model_name)\n",
      "c:\\Users\\nicol\\OneDrive\\MIA\\Cursos\\SEGUNDO BIMESTRE\\PROYECTO APLICADO\\PROYECTO\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Generar embeddings para los chunks\n",
    "embeddings , embedding_model = generate_embeddings([chunk.page_content for chunk in chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 embeddings guardados en formato JSON en la carpeta: ../Castro_Cofre_Zurita/data/embeddings\n"
     ]
    }
   ],
   "source": [
    "output_folder = \"../Castro_Cofre_Zurita/data/embeddings\"\n",
    "save_embeddings_as_json(embeddings, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones del embedding: 384\n"
     ]
    }
   ],
   "source": [
    "# Verificar las dimensiones del embedding\n",
    "sample_embedding = embedding_model.embed_query(\"test query\")\n",
    "print(f\"Dimensiones del embedding: {len(sample_embedding)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Este módulo contiene funciones para crear y gestionar una base de datos vectorial utilizando Qdrant.\"\"\"\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_qdrant import QdrantVectorStore, RetrievalMode\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "\n",
    "# Cargar las variables de entorno\n",
    "load_dotenv()\n",
    "\n",
    "def create_qdrant_vector_store(docs: list, embedding_model, collection_name: str = \"demo_collection\", path: str = \"/tmp/langchain_qdrant\", vector_size: int = 384) -> QdrantVectorStore:\n",
    "    \"\"\"\n",
    "    Crea una base de datos vectorial en Qdrant y almacena documentos con sus embeddings.\n",
    "\n",
    "    Args:\n",
    "        docs: Lista de documentos (chunks) a almacenar en la base de datos.\n",
    "        embedding_model: Modelo de embeddings a utilizar para calcular vectores.\n",
    "        collection_name: Nombre de la colección en Qdrant (por defecto, \"demo_collection\").\n",
    "        path: Ruta donde se almacenará la base de datos Qdrant (por defecto, \"/tmp/langchain_qdrant\").\n",
    "        vector_size: Tamaño de los vectores de embedding (por defecto, 768).\n",
    "\n",
    "    Returns:\n",
    "        qdrant_store: Objeto QdrantVectorStore listo para realizar búsquedas.\n",
    "    \"\"\"\n",
    "    # Inicializar el cliente Qdrant\n",
    "    client = QdrantClient(path=path)\n",
    "\n",
    "    # Eliminar la colección existente si ya existe\n",
    "    client.delete_collection(collection_name=collection_name)\n",
    "\n",
    "    # Crear una nueva colección en Qdrant\n",
    "    client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=VectorParams(size=vector_size, distance=Distance.COSINE),\n",
    "    )\n",
    "\n",
    "    # Crear un QdrantVectorStore\n",
    "    vector_store = QdrantVectorStore(\n",
    "        client=client,\n",
    "        collection_name=collection_name,\n",
    "        embedding=embedding_model,\n",
    "    )\n",
    "\n",
    "    # Agregar documentos a la colección\n",
    "    vector_store.add_documents(docs)\n",
    "\n",
    "    print(f\"Base de datos vectorial '{collection_name}' creada y {len(docs)} documentos añadidos.\")\n",
    "\n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_documents(query: str, vector_store, k: int = 5) -> list:\n",
    "    \"\"\"\n",
    "    Recupera los documentos más relevantes para una consulta dada utilizando QdrantVectorStore.\n",
    "\n",
    "    Args:\n",
    "        query: Texto de la consulta.\n",
    "        vector_store: Objeto QdrantVectorStore donde se encuentran almacenados los documentos.\n",
    "        k: Número de documentos relevantes a recuperar (por defecto, 5).\n",
    "\n",
    "    Returns:\n",
    "        docs: Lista de los documentos más relevantes encontrados para la consulta.\n",
    "    \"\"\"\n",
    "    # Realizar la búsqueda de similitud en el vector store\n",
    "    docs = vector_store.similarity_search(query, k=k)\n",
    "\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (384,) into shape (1536,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Crear base de datos vectorial\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_qdrant_vector_store\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Realizar una búsqueda\u001b[39;00m\n\u001b[0;32m      5\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat are the labeling regulations for food products in Brazil?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[16], line 45\u001b[0m, in \u001b[0;36mcreate_qdrant_vector_store\u001b[1;34m(docs, embedding_model, collection_name, path, vector_size)\u001b[0m\n\u001b[0;32m     38\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m QdrantVectorStore(\n\u001b[0;32m     39\u001b[0m     client\u001b[38;5;241m=\u001b[39mclient,\n\u001b[0;32m     40\u001b[0m     collection_name\u001b[38;5;241m=\u001b[39mcollection_name,\n\u001b[0;32m     41\u001b[0m     embedding\u001b[38;5;241m=\u001b[39membedding_model,\n\u001b[0;32m     42\u001b[0m )\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Agregar documentos a la colección\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m \u001b[43mvector_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBase de datos vectorial \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcollection_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m creada y \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(docs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m documentos añadidos.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vector_store\n",
      "File \u001b[1;32mc:\\Users\\nicol\\OneDrive\\MIA\\Cursos\\SEGUNDO BIMESTRE\\PROYECTO APLICADO\\PROYECTO\\.venv\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:287\u001b[0m, in \u001b[0;36mVectorStore.add_documents\u001b[1;34m(self, documents, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m     texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m    286\u001b[0m     metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m--> 287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    288\u001b[0m msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`add_documents` and `add_texts` has not been implemented \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    291\u001b[0m )\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n",
      "File \u001b[1;32mc:\\Users\\nicol\\OneDrive\\MIA\\Cursos\\SEGUNDO BIMESTRE\\PROYECTO APLICADO\\PROYECTO\\.venv\\Lib\\site-packages\\langchain_qdrant\\qdrant.py:444\u001b[0m, in \u001b[0;36mQdrantVectorStore.add_texts\u001b[1;34m(self, texts, metadatas, ids, batch_size, **kwargs)\u001b[0m\n\u001b[0;32m    440\u001b[0m added_ids \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_ids, points \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_batches(\n\u001b[0;32m    442\u001b[0m     texts, metadatas, ids, batch_size\n\u001b[0;32m    443\u001b[0m ):\n\u001b[1;32m--> 444\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m     added_ids\u001b[38;5;241m.\u001b[39mextend(batch_ids)\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m added_ids\n",
      "File \u001b[1;32mc:\\Users\\nicol\\OneDrive\\MIA\\Cursos\\SEGUNDO BIMESTRE\\PROYECTO APLICADO\\PROYECTO\\.venv\\Lib\\site-packages\\qdrant_client\\qdrant_client.py:1508\u001b[0m, in \u001b[0;36mQdrantClient.upsert\u001b[1;34m(self, collection_name, points, wait, ordering, shard_key_selector, **kwargs)\u001b[0m\n\u001b[0;32m   1480\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1481\u001b[0m \u001b[38;5;124;03mUpdate or insert a new point into the collection.\u001b[39;00m\n\u001b[0;32m   1482\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;124;03m    Operation Result(UpdateResult)\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown arguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1508\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mordering\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mordering\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshard_key_selector\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshard_key_selector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1514\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1515\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nicol\\OneDrive\\MIA\\Cursos\\SEGUNDO BIMESTRE\\PROYECTO APLICADO\\PROYECTO\\.venv\\Lib\\site-packages\\qdrant_client\\local\\qdrant_local.py:770\u001b[0m, in \u001b[0;36mQdrantLocal.upsert\u001b[1;34m(self, collection_name, points, **kwargs)\u001b[0m\n\u001b[0;32m    766\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupsert\u001b[39m(\n\u001b[0;32m    767\u001b[0m     \u001b[38;5;28mself\u001b[39m, collection_name: \u001b[38;5;28mstr\u001b[39m, points: types\u001b[38;5;241m.\u001b[39mPoints, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[0;32m    768\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m types\u001b[38;5;241m.\u001b[39mUpdateResult:\n\u001b[0;32m    769\u001b[0m     collection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_collection(collection_name)\n\u001b[1;32m--> 770\u001b[0m     \u001b[43mcollection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_default_update_result()\n",
      "File \u001b[1;32mc:\\Users\\nicol\\OneDrive\\MIA\\Cursos\\SEGUNDO BIMESTRE\\PROYECTO APLICADO\\PROYECTO\\.venv\\Lib\\site-packages\\qdrant_client\\local\\local_collection.py:2165\u001b[0m, in \u001b[0;36mLocalCollection.upsert\u001b[1;34m(self, points)\u001b[0m\n\u001b[0;32m   2163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(points, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m   2164\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m point \u001b[38;5;129;01min\u001b[39;00m points:\n\u001b[1;32m-> 2165\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_upsert_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2166\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(points, models\u001b[38;5;241m.\u001b[39mBatch):\n\u001b[0;32m   2167\u001b[0m     batch \u001b[38;5;241m=\u001b[39m points\n",
      "File \u001b[1;32mc:\\Users\\nicol\\OneDrive\\MIA\\Cursos\\SEGUNDO BIMESTRE\\PROYECTO APLICADO\\PROYECTO\\.venv\\Lib\\site-packages\\qdrant_client\\local\\local_collection.py:2157\u001b[0m, in \u001b[0;36mLocalCollection._upsert_point\u001b[1;34m(self, point)\u001b[0m\n\u001b[0;32m   2155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_point(point)\n\u001b[0;32m   2156\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2157\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mpersist(point)\n",
      "File \u001b[1;32mc:\\Users\\nicol\\OneDrive\\MIA\\Cursos\\SEGUNDO BIMESTRE\\PROYECTO APLICADO\\PROYECTO\\.venv\\Lib\\site-packages\\qdrant_client\\local\\local_collection.py:2065\u001b[0m, in \u001b[0;36mLocalCollection._add_point\u001b[1;34m(self, point)\u001b[0m\n\u001b[0;32m   2063\u001b[0m     norm \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(vector_np)\n\u001b[0;32m   2064\u001b[0m     vector_np \u001b[38;5;241m=\u001b[39m vector_np \u001b[38;5;241m/\u001b[39m norm \u001b[38;5;28;01mif\u001b[39;00m norm \u001b[38;5;241m>\u001b[39m EPSILON \u001b[38;5;28;01melse\u001b[39;00m vector_np\n\u001b[1;32m-> 2065\u001b[0m \u001b[43mnamed_vectors\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m vector_np\n\u001b[0;32m   2066\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectors[vector_name] \u001b[38;5;241m=\u001b[39m named_vectors\n\u001b[0;32m   2067\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeleted_per_vector[vector_name] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m   2068\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeleted_per_vector[vector_name], \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   2069\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (384,) into shape (1536,)"
     ]
    }
   ],
   "source": [
    "# Crear base de datos vectorial\n",
    "vector_store = create_qdrant_vector_store(chunks, embedding_model)\n",
    "\n",
    "# Realizar una búsqueda\n",
    "query = \"What are the labeling regulations for food products in Brazil?\"\n",
    "results = retrieve_documents(query, vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[155], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresults\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1:\n",
      "page_content='Lei 11.265/2006 – Regulamenta a comercialização de alimentos para lactentes e crianças de primeira infância \n",
      "e a de produtos de puericultura correlatos. \n",
      " Alterada por: \n",
      "Lei 11.474/2007  – Altera a Lei no 10.188, de 12 de fevereiro de 2001, que cria o Programa de \n",
      "Arrendamento Residencial, institui o arrendamento residencial com opção de compra, e a Lei no \n",
      "11.265, de 3 de janeiro de 2006, que regulamenta a comercialização de alimentos para lactentes e \n",
      "crianças de primeira infância e a de produtos de puericultura correlatos, e dá outras providências. \n",
      "Ato relacionado: \n",
      "Decreto 9.579/2018 – Consolida atos normativos editados pelo Poder Executivo federal que dispõem \n",
      "sobre a temática do lactente, da criança e do adolescente e do aprendiz, e sobre o Conselho Nacional \n",
      "dos Direitos da Criança e do Adolescente, o Fundo Nacional para a Criança e o Adolescente e os \n",
      "programas federais da criança e do adolescente.' metadata={'_id': '83243dd0c138437aa29487984d0ee2e9', '_collection_name': 'demo_collection'}\n",
      "\n",
      "Result 2:\n",
      "page_content='alimentos embalados. \n",
      "Decreto-Lei 986/1969 – Institui normas básicas sobre alimentos. \n",
      "Alterado por: \n",
      "Lei 13.305/2016 – Altera Decreto-Lei 986/1969 para dispor sobre rotulagem de alimentos com lactose. \n",
      " \n",
      "Decreto 4.680/2003 – Regulamenta o direito à informação  quanto aos alimentos e ingredientes alimentares \n",
      "destinados ao consumo humano ou animal que contenham ou sejam produzidos a partir de organismos \n",
      "geneticamente modificados. \n",
      " Ato relacionado: \n",
      "Portaria MJ 2.658/2003 – Define o símbolo de que trata o art. 2º, § 1º, do Decreto 4.680, de 24 de abril \n",
      "de 2003. \n",
      " \n",
      "Lei 10.674/2003  – Obriga a que os produtos alimentícios comercializados informem sobre a presença de \n",
      "glúten, como medida preventiva e de controle da doença celíaca. \n",
      " \n",
      "Lei 11.265/2006 – Regulamenta a comercialização de alimentos para lactentes e crianças de primeira infância \n",
      "e a de produtos de puericultura correlatos. \n",
      " Alterada por:' metadata={'_id': '1b6357fa9d2f472484a4aec942696704', '_collection_name': 'demo_collection'}\n",
      "\n",
      "Result 3:\n",
      "page_content='2.2. Informações sobre fenilalanina em alimentos \n",
      " \n",
      "RDC 617/2022 - Obrigatoriedade da realização de análises laboratoriais e da transmissão de informações sobre \n",
      "os teores de fenilalanina, proteínas e umidade em alimentos industrializados. \n",
      "Documento relacionado: \n",
      "Perguntas e Respostas sobre Análise de Fenilalanina em Alimentos  \n",
      "2.3. Promoção comercial e publicidade em alimentos \n",
      " \n",
      "Decreto-Lei 986/1969 – Institui normas básicas sobre alimentos. \n",
      "Lei 11.265/2006 – Regulamenta a comercialização de alimentos para lactentes e crianças de primeira infância \n",
      "e também a de produtos de puericultura correlatos. \n",
      " Alterada por: \n",
      "Lei 11.474/2007 \n",
      "Ato relacionado:   \n",
      " \n",
      "Decreto 9.579/2018 – Consolida atos normativos editados pelo Poder Executivo federal que dispõem \n",
      "sobre a temática do lactente, da criança e do adolescente e do aprendiz, e sobre o Conselho Nacional \n",
      "dos Direitos da Criança e do Adolescente, o Fundo Nacional para a Criança e o Adolescente e os' metadata={'_id': 'afe54eef66b74b878b60a8147c8d56b9', '_collection_name': 'demo_collection'}\n",
      "\n",
      "Result 4:\n",
      "page_content='Atos relacionados: \n",
      "Lei 12.849/2013 – Obrigatoriedade de as fábricas de produtos que contenham látex natural gravarem \n",
      "em suas embalagens advertência sobre a presença dessa substância. \n",
      "RDC 902/2024  - Inclusão de declaração sobre nova fórmula na rotulagem de produtos sujeitos à \n",
      "vigilância sanitária quando da alteração de sua composição. \n",
      "Guia nº 5, versão 2, de 16/10/2018 - Guia sobre Programa de Controle de Alergênicos. \n",
      "Guia nº 16, versão 1, de 05/10/2018 - Guia para Determinação de Prazos de Validade de Alimentos. \n",
      " Documentos relacionados: \n",
      "Perguntas e respostas sobre rotulagem de alimentos alergênicos \n",
      "Perguntas e respostas sobre rotulagem de lactose \n",
      "Perguntas e Respostas sobre Rotulagem de Nova Fórmula \n",
      "4.3. Recolhimento de alimentos  \n",
      " \n",
      "RDC 655/2022 - Recolhimento de alimentos e sua comunicação à Anvisa e aos consumidores.    \n",
      " \n",
      "4.4. Nutrivigilância \n",
      " \n",
      "Tema Regulatório 3.4 da Agenda Regulatória 2024/2025 - A regulamentar.' metadata={'_id': '434d40c2e2d8445c858b8a3e0337a4fc', '_collection_name': 'demo_collection'}\n",
      "\n",
      "Result 5:\n",
      "page_content='de tecnologia  \n",
      " \n",
      "Tema Regulatório 3.5 da Agenda Regulatória 2024/2025: Reavaliação da autorização de uso do aditivo  \n",
      "alimentar dióxido de titânio em alimentos. \n",
      "Tema Regulatório 3.9 da Agenda Regulatória 2024/2025: Regulamentação dos aditivos corantes formulados \n",
      "e da rotulagem de corantes e aromatizantes em alimentos embalados. \n",
      "Tema Regulatório 3.14 da Agenda Regulatória 2024/2025: Revisão da regulamentação de aditivos  \n",
      "alimentares e coadjuvantes de tecnologia autorizados para uso em produtos lácteos. \n",
      "Tema Regulatório 3.15 da Agenda Regulatória 2024/2025: Revisão da regulamentação de aditivos  \n",
      "alimentares e coadjuvantes de tecnologia em alimentos. \n",
      "Tema Regulatório 3.16 da Agenda Regulatória 2024/2025: Revisão da regulamentação de autorização de uso \n",
      "e de rotulagem de aditivos edulcorantes em alimentos. \n",
      "Tema Regulatório 3.34 da Agenda Regulatória 2024/2025: Atualização periódica das listas de aditivos' metadata={'_id': 'dcce6196b557475faa61f5fcf08fad26', '_collection_name': 'demo_collection'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example query 2\n",
    "query = \"Quais são as normas para lactantes no Brasil?\"\n",
    "results = retrieve_documents(query,vector_store)\n",
    "\n",
    "# Display results\n",
    "for i, doc in enumerate(results):\n",
    "    print(f\"Result {i + 1}:\\n{doc}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1:\n",
      "page_content='BIBLIOTECA DE \n",
      "ALIMENTOS \n",
      "Atualizada em 06.11.2024 \n",
      "Coordenação de Processos Regulatórios – CPROR \n",
      "Assessoria de Melhoria da Qualidade Regulatória – ASREG \n",
      "Gabinete do Diretor-Presidente \n",
      " \n",
      "AGENDA REGULATÓRIA \n",
      "Ciclo Bienal \n",
      "2024-2025   \n",
      " \n",
      "APRESENTAÇÃO \n",
      " \n",
      " As Bibliotecas são documentos que reúnem todas as normas vigentes de determinado \n",
      "macrotema, divididos por temas. O objetivo é facilitar o acesso e a compreensão do Estoque \n",
      "Regulatório ao público interno e externo, bem como aprimorar o processo de elaboração e \n",
      "revisão das normativas. \n",
      " \n",
      " \n",
      "Não deixe de consultar também a Biblioteca de Temas Transversais, que abrange assuntos \n",
      "aplicados a todos os macrotemas, tais como: Autorização de Funcionamento de Empresa \n",
      "(AFE), Certificação de Boas Práticas de Fabricação (CBPF), Taxas de Fiscalização de Vigilância \n",
      "Sanitária (TFVS), Peticionamento de Recursos, etc. \n",
      " \n",
      "  \n",
      "No setor de alimentos, a Anvisa coordena, supervisiona e controla as atividades de registro, inspeção,' metadata={'_id': 'f5d27bb0dba34ef4956f153164760ce7', '_collection_name': 'demo_collection'}\n",
      "\n",
      "Result 2:\n",
      "page_content='Tema Regulatório 3.6 da Agenda Regulatória 2024/2025: Regulamentação da declaração quantitativa de  \n",
      "ingredientes na rotulagem de alimentos embalados. \n",
      "Tema Regulatório 3.9 da Agenda Regulatória 2024/2025: Regulamentação dos aditivos corantes formulados \n",
      "e da rotulagem de corantes e aromatizantes em alimentos embalados. \n",
      "Tema Regulatório 3.16 da Agenda Regulatória 2024/2025: Revisão da regulamentação de autorização de uso \n",
      "e de rotulagem de aditivos edulcorantes em alimentos.   \n",
      " \n",
      "Tema Regulatório 3.23 da Agenda Regulatória 2024/2025: Revisão da regulamentação sobre rotulagem  dos \n",
      "principais alimentos alergênicos. \n",
      "Tema Regulatório 3.24 da Agenda Regulatória 2024/2025: Revisão da regulamentação sobre rotulagem geral \n",
      "de alimentos embalados. \n",
      "Tema 3.25 da Agenda Regulatória 2024/2025: Revisão da regulamentação sobre rotulagem  nutricional dos \n",
      "alimentos embalados. \n",
      "Decreto-Lei 986/1969 – Institui normas básicas sobre alimentos. \n",
      "Alterado por:' metadata={'_id': 'b1db3f9037104a379101f9093852a10d', '_collection_name': 'demo_collection'}\n",
      "\n",
      "Result 3:\n",
      "page_content='RDC 843/2024 - Regularização de alimentos e embalagens sob competência do Sistema Nacional de Vigilância \n",
      "Sanitária (SNVS) destinados à oferta no território nacional.  \n",
      " \n",
      "IN 281/2024 - Forma de regularização das diferentes categorias de alimentos e embalagens, e a respectiva \n",
      "documentação que deve ser apresentada.    \n",
      " \n",
      "1.2. Procedimentos para avaliação de risco, segurança e eficácia de alimentos  \n",
      " \n",
      "Tema Regulatório 3.8 da Agenda Regulatória 2024/2025: Regulamentação das listas de novos alimentos e  \n",
      "novos ingredientes autorizados e suas especificações. \n",
      "RES 18/1999 – Análise e comprovação de propriedades funcionais e ou de saúde alegadas em rotulagem de \n",
      "alimentos. \n",
      "Alterada por: \n",
      "RDC 843/2024 - Regularização de alimentos e embalagens sob competência do Sistema Nacional de \n",
      "Vigilância Sanitária (SNVS) destinados à oferta no território nacional. \n",
      "Atos relacionados: \n",
      "RDC 241/2018 – Requisitos para comprovação da segurança e dos benefícios à saúde dos probióticos' metadata={'_id': '8b76671330224d1bbb343f996789cd51', '_collection_name': 'demo_collection'}\n",
      "\n",
      "Result 4:\n",
      "page_content='Sanitária (TFVS), Peticionamento de Recursos, etc. \n",
      " \n",
      "  \n",
      "No setor de alimentos, a Anvisa coordena, supervisiona e controla as atividades de registro, inspeção, \n",
      "fiscalização e controle de riscos, sendo responsável por estabelecer normas e padrões de qualidade e \n",
      "identidade a serem observados. \n",
      "O objetivo é garantir a segurança e a qualidade de alimentos, incluindo bebidas, águas envasadas, \n",
      "ingredientes, matérias-primas, aditivos alimentares e coadjuvantes de tecnologia, materiais em contato \n",
      "com alimentos, contaminantes, resíduos de medicamentos veterinários, rotulagem e inovações \n",
      "tecnológicas em produtos da área de alimentos.   \n",
      " \n",
      "Sumário \n",
      "1. Regularização, avaliação de risco e padrões de alimentos ................................ ................................ .........................  4 \n",
      "1.1. Procedimentos para regularização de alimentos ................................ ................................ ............................  4' metadata={'_id': 'f04fb62be6f34d49a5f6c884cca7b983', '_collection_name': 'demo_collection'}\n",
      "\n",
      "Result 5:\n",
      "page_content='dos Direitos da Criança e do Adolescente, o Fundo Nacional para a Criança e o Adolescente e os \n",
      "programas federais da criança e do adolescente. \n",
      " \n",
      "INC 9/2002 – Embalagens destinadas ao acondicionamento de produtos hortícolas ''in natura''. \n",
      " \n",
      "RDC 21/2001 – Regulamento técnico para irradiação de alimentos. \n",
      " \n",
      "RDC 429/2020 - Rotulagem nutricional dos alimentos embalados.   \n",
      "Alterada por: \n",
      "RDC 460/2020 - Requisitos sanitários das fórmulas dietoterápicas para erros inatos do metabolismo.  \n",
      "RDC 729/2022 - Melhora da técnica legislativa e revogação de normas inferiores a Decreto editadas \n",
      "pela ANVISA, componentes da quinta etapa de consolidação da pertinência temática de alimentos em \n",
      "observância ao que prevê a Portaria nº 488/GADIP -DP/ANVISA, de 23 de setembro de 2021 e o \n",
      "Decreto nº 10.139, de 28 de novembro de 2019.   \n",
      " \n",
      "RDC 819/2023 \n",
      "Ato relacionado: \n",
      "IN 75/2020 - Estabelece os requisitos técnicos para declaração da rotulagem nutricional nos alimentos \n",
      "embalados.' metadata={'_id': 'ba67c07481234b3c87105d23046e1fa8', '_collection_name': 'demo_collection'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example query \n",
    "query = \"what about alcoholic normas?\" #   \"\"Quais são as normas de bebidas alcoólicas no Brasil?\"\n",
    "results = retrieve_documents(query,vector_store)\n",
    "\n",
    "# Display results\n",
    "for i, doc in enumerate(results):\n",
    "    print(f\"Result {i + 1}:\\n{doc}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
